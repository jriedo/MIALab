\documentclass[journal]{IEEEtran}

\usepackage[pdftex]{graphicx}
\graphicspath{{img/}}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{booktabs,siunitx}
\usepackage{threeparttable}
%\usepackage{subcaption}
\usepackage{multirow}
\usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}

\usepackage{endfloat}

% TODO: remove
	\usepackage{xcolor}
	\newcommand\TODO[1]{\textcolor{red}{TODO: #1}}
	\newcommand\FIXME[1]{\textcolor{blue}{FIXME: #1}}

\begin{document}
\title{Title of the Paper}


\author{Michael~Mueller,
        Jan~Riedo,
        Michael~Rebsamen% <-this % stops a space
\thanks{Biomedical Engineering, University of Bern}% <-this % stops a space
\thanks{Authors e-Mail: michael.mueller4@students.unibe.ch, jan.riedo@students.unibe.ch, michael.rebsamen@students.unibe.ch}}% <-this % stops a space
\markboth{Biomedical Engineering, Medical Image Analysis Lab, \today}%
{Title of the Paper}
\maketitle

\begin{abstract}
Bla
\end{abstract}
\begin{IEEEkeywords}
MRI, Segmentation, Machine Learning, DF, kNN, SVM
\end{IEEEkeywords}


\section{Introduction}
Segmentation of brain tissues from magnetic resonance images (MRI) has many clinical applications. Clinicians gain useful information from a separation of tissue into its three main anatomical types: white matter, grey matter, and ventricles. However, manual segmentation of MRI is a labour-intensive task requiring expert skills. Fully automatic approaches for brain tissue segmentation are therefore a topic of active research. A good algorithm classifies the tissue types with high accuracy across a variety of images from different patients. Such a classification is a typical task for machine learning. These algorithms tend to perform well given enough training data during the learning phase. The availability of ground-truth data in sufficient quantity and quality for supervised learning is a particular challenge when working with medical images due to privacy concerns and the costs for manual segmentation. Optimization of the learning phase with a limited number of training data is therefore required.

\FIXME{kNN is a popular classification method for MR data and has successfully been applied in MR brain segmentation\cite{Anbeek2004,Cocosco2003,Warfield2000}}

\FIXME{Base paper on df \cite{Breiman2001}.}


\section{Methods}

\subsection{Dataset}
All experiments were conducted on a subset of 100 unrelated subjects from a dataset provided by the \textit{Human Connectome Project} \cite{van2013wu}. From each individual, a total of eight 3-tesla head MRI are available: T1 and T2-weighted image volumes not skull-stripped (but defaced for anonymization) and skull-stripped with a bias field correction, and both modalities once in native T1 space and once in MNI-atlas space \cite{mazziotta2001probabilistic}.

Ground-truth labels are automatically generated using \textit{FreeSurf}, assigning each voxel either to background, white matter, grey matter, or ventricles. The dataset was split in a training set with 70 images and a test set with 30 images.
\subsection{Pipeline}
\TODO{Describe whole pipeline (registration, pre-processing, feature extraction, ML classification, post-processing, evaluation}
\FIXME{During feature extraction, a random mask is applied in order to randomly select a fraction of the voxels available. The mask is adjustable individually for background, white matter, grey matter, and ventricles. It is crucial to optimize those parameters in order to obtain the best result.}

\subsection{Training}
\TODO{Describe training of machine learning algorithms}
\TODO{SVM gridsearch for hyperparameter tuning?}

\subsection{Performance Evaluation}
\TODO{Describe metric (dice score)}

\subsection{Infrastructure}
\TODO{Describe UBELIX, libraries}


\section{Results}
All algorithms tested and optimized were able to yield a good result for brain segmentation. The performance measured with the dice coefficient can be found in Tab.~(\ref{tab:perf_compare}). Comparisons of computation time can be seen in Tab.~(\ref{tab:time_compare}).\\

\subsection{Ground Truth Validity}

The importance of looking at the images and not only at the numbers shall be presented based on one example MRI image, segmented with kNN. In Fig.~(\ref{f.ground_truth}) we see one slice of a brain, segmented in three different ways. On the left, we see a kNN segmentation based on non-coordinate features. The one in the middle is segmented with kNN based on all features. On the right we see the ground truth. Although the middle image shows a substantially better result in ventricle dice than the left (0.68 vs. 0.76) we can barely see an improved ventricle segmentation with bare eyes. What we see however, is a big difference on how detailed the white and grey matter are segmented, thus leading to a better overall segmentation. Another fact which shall be presented here is that the ground truth image is not a real ground truth. It is an image segmented by another algorithm. In Fig~(\ref{f.knn_a}) a better segmentation of the center part (white matter) is achieved compared to the ground truth image in Fig~(\ref{f.knn_c}) (background).

\begin{figure*}
	\centering
	\subfloat[]{\includegraphics[width=0.3\linewidth]{images/knn_no_coord}\label{f.knn_a}}
	\hfill
	\subfloat[]{\includegraphics[width=0.3\linewidth]{images/knn_all}}
	\hfill
	\subfloat[]{\includegraphics[width=0.3\linewidth]{images/knn_ground_truth}\label{f.knn_c}}
	\caption{(a) kNN segmented image based on non-coordinate features with dice values 0.86/0.82/0.68. (b) kNN segmented image based on all features with dice values 0.80/0.79/0.76. (c) Ground truth.}
	\label{f.ground_truth}
\end{figure*}

\subsection{Feature Inspection}

Feature selection is another key part of the machine learning process. Features are also called variable or attribute and describe the model. Irrelevant and redundant features do not contribute to the accuracy of the predictive model, at worst they decrease the accuracy. The used feature set consists of seven features, f1-f3: Coordinate features, f4: T1 intensity, f5: T1 gradient, f6: T2 intensity, f7: T2 gradient. The following Fig~(\ref{scatterplot}) shows the scatter matrix of all the features. On the diagonal are the histograms for each feature. The right upper part of the diagonal visualizes the linear correlation between each of the feature with the associated correlation coefficient. The left bottom part of the diagonal is redundant to the upper part. There is a moderate uphill relationship for the feature f4 \& f5, f5 \& f6, f5 \& f7. A strong uphill linear relationship for coefficients over 0.7, in this case for the feature f6 \& f7. This imply, that only the the first three feature, the coordinates, are independent.

\begin{figure}
	\centering
	\includegraphics[width=0.48\textwidth]{images/ScatterPlotMatrix}
	\caption{Scatter plot of the features with correlation coefficient}
	\label{scatterplot}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=0.48\textwidth]{images/DF_FE_WSF_PP}
	\caption{Feature evaluation with Decision Forest by removing a single feature and with preprocessing}
	\label{DF_FeatEval_WSF_PP}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.48\textwidth]{images/DF_FE_WSF_NPP}
	\caption{Feature evaluation with Decision Forest by removing a single feature and without preprocessing}
	\label{DF_FeatEval_WSF_NPP}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.48\textwidth]{images/DF_FE_SF_PP}
	\caption{Feature evaluation with Decision Forest by using a single feature and with preprocessing }
	\label{DF_FeatEval_SF_PP}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.48\textwidth]{images/DF_FE_SF_NPP}
	\caption{Feature evaluation with Decision Forest by using a single feature and without preprocessing }
	\label{DF_FeatEval_SF_NPP}
\end{figure}

\subsection{Random Mask Optimization}

One major task to handle was the low value for the ventricles. Dice values above 0.5 were hard to achieve. One way to improve the dice for ventricles was to optimize the random mask with respect to the fraction of ventricle voxels taken into account. The effects of the random mask on the ventricle dice can be seen in Fig.~(\ref{f.random_mask}). Best results were achieved with a fraction of 0.004 ventricles, approximately the same fraction as for white matter and grey matter. All following results are based on this optimized mask.
\begin{figure}[h!]
	\centering
	\subfloat[]{\includegraphics[width=0.3\linewidth]{images/ven_0_4}}
	\hfill
	\subfloat[]{\includegraphics[width=0.3\linewidth]{images/ven_0_04}}
	\hfill
	\subfloat[]{\includegraphics[width=0.3\linewidth]{images/ven_0_004}}
	\caption{Optimization of the random mask parameter for ventricles. Fraction of ventricle voxels taken into account $f_v$ and dice value for this certain parameter $d_v$ are: ($f_v$ / $d_v$) (a) 0.4 / 0.22, (b) 0.04 / 0.44, and (c) 0.004 / 0.62.}
	\label{f.random_mask}
\end{figure}


\subsection{Algorithm Performance}



The decision forest algorithm was enhanced with normalized features, a higher number of ventricle voxels in the training set and the optimization of the hyperparameters (see Fig.~\ref{f.df_white}). With this settings, the max dice coefficient was lifted from 0.703 to 0.754. This result was achieved with 80 trees and 3000 max nodes.

\begin{figure}[h!]\label{f.df_white}
	\centering
	\includegraphics[width=0.48\textwidth]{images/df_grid}
	\caption{DF plot of grid search for white matter, grey matter and ventricles. The red cross marks the chosen hyperparameters number of trees~=~160 and maximum nodes per tree~=~3000. Color does not represent dice, the data is stretched individually for all three plots.}
\end{figure}



Statistical distribution of the dice coefficients can be seen in Fig. \ref{f.boxplot}. DF and SVM achieve a similar mean dice score but SVM has a lower variance for the ventricles.
\begin{figure}\label{f.boxplot}
	\centering
	\includegraphics[width=0.48\textwidth]{images/boxplot}
	\caption{Distribution of dice coefficients with optimal hyper-parameters for each algorithm on the full training set of 70 images.}
\end{figure}

Comparison of computation time for training and testing is shown in Fig. \ref{f.runtimebarplot}.
\begin{figure}\label{f.runtimebarplot}
	\centering
	\includegraphics[width=0.48\textwidth]{images/runtimes}
	\caption{Time for training and testing of the algorithms with training set sizes of 3, 12 and 70 samples. Test time is for one sample.}
\end{figure}


\begin{table*}[t]
\renewcommand{\arraystretch}{1.2}
\newcommand\mulrow[2]{\multirow{#1}{*}{\shortstack[c]{#2}}}
\caption{Performance Comparison of ML Algorithms}
\label{tab:perf_compare}
\centering
\begin{threeparttable}
\begin{tabular*}{0.9\textwidth}{@{\extracolsep{\fill}}c*{7}{S[table-number-alignment=center,table-figures-decimal=2,table-auto-round]}@{}}
\toprule
Features & {Size Dataset} & {\shortstack[c]{DF}} & {\shortstack[c]{GMM}} & {\shortstack[c]{kNN}} & {\shortstack[c]{SGD}} & {\shortstack[c]{SVM}} & {\shortstack[c]{ensemble}}\\
\midrule
\mulrow{3}{All\\(f1-f7)}
	& 3		&	{0.85/0.81/0.62}		& {-}	& {0.70/0.57/0.50}	& {0.82/0.80/0.35}	& {0.83/0.80/0.61}	& {-}\\
	& 12		&	{0.85/0.81/0.59}		& {-}	& {0.75/0.66/0.67}	& {0.82/0.80/0.33}	& {0.84/0.81/0.61}	& {-}\\
	& 70		&	{0.85/0.80/0.60}		& {-}	& {0.80/0.76/0.72}	& {0.82/0.80/0.33}	& {0.84/0.82/0.61}	& {0.82/0.79/0.71}\\
\midrule
\mulrow{3}{Coordinates only\\(f1-f3)}
	& 3		&	{-}		& {-}	& {0.70/0.55/0.41}	& {-}	& {-}	& {-}\\
	& 12		&	{-}		& {-}	& {0.74/0.63/0.56}	& {-}	& {-}	& {-}\\
	& 70		&	{-}		& {-}	& {0.77/0.71/0.62}	& {-}	& {-}	& {-}\\
\midrule
\mulrow{3}{All non-coordinates \\(f4-f7)}
	& 3		&	{-}		& {-}	& {0.85/0.80/0.45}	& {-}	& {-}	& {-}\\
	& 12		&	{-}		& {-}	& {0.85/0.81/0.45}	& {-}	& {-}	& {-}\\
	& 70		&	{-}		& {-}	& {0.85/0.81/0.54}	& {-}	& {-}	& {-}\\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item Overview of achieved accuracy for the different algorithms. Mean dice scores for white matter/grey matter/ventricles.
\item f1-f3: Coordinate features, f4: T1 intensity, f5: T1 gradient, f6: T2 intensity, f7: T2 gradient.
\end{tablenotes}
\end{threeparttable}
\end{table*}

\begin{table*}[t]
\renewcommand{\arraystretch}{1.2}
\newcommand\mulrow[2]{\multirow{#1}{*}{\shortstack[c]{#2}}}
\caption{Runtime}
\label{tab:time_compare}
\centering
\begin{threeparttable}
\begin{tabular*}{0.9\textwidth}{@{\extracolsep{\fill}}c*{6}{S[table-number-alignment=center,table-figures-decimal=2,table-auto-round]}@{}}
\toprule
Features & {Size Dataset} & {\shortstack[c]{DF}} & {\shortstack[c]{GMM}} & {\shortstack[c]{kNN}} & {\shortstack[c]{SGD}} & {\shortstack[c]{SVM}}\\
\midrule
\mulrow{3}{All\\(f1-f7)}
	& 3		&	{205.4/22310.2}		& {-}	& {13.4/7023.7}	& {216.9/1126.5}	& {15.1/7289.7}\\
	& 12		&	{258.7/16563.6}		& {-}	& {38.1/7090.0}	& {875.0/903.8}	& {48.2/18730.5}\\
	& 70		&	{401.4/16116.2}		& {-}	& {215.5/8873.5}	& {5753.3/1010.6}	& {448.1/79668.4}\\
\midrule
\mulrow{3}{Coordinates only\\(f1-f3)}
	& 3		&	{-}		& {-}	& {10.4/4391.5}	& {-}	& {-}\\
	& 12		&	{-}		& {-}	& {34.7/5449.3}	& {-}	& {-}\\
	& 70		&	{-}		& {-}	& {196.4/6112.8}	& {-}	& {-}\\
\midrule
\mulrow{3}{All non-coordinates \\(f4-f7)}
	& 3		&	{-}		& {-}	& {10.1/10084.7}	& {-}	& {-}\\
	& 12		&	{-}		& {-}	& {34.6/18768.6}	& {-}	& {-}\\
	& 70		&	{-}		& {-}	& {194.2/16555.7}	& {-}	& {-}\\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item \FIXME{Overview of the computation time in seconds for all algorithms (training time/testing time). Computation time includes pre- and post-processing.}
\end{tablenotes}
\end{threeparttable}
\end{table*}


\section{Discussion}
\TODO{challenge with quality of ground truth}

\TODO{feature importance}


\section{Conclusion}

\section*{Acknowledgment}
Calculations were performed on UBELIX (http://www.id.unibe.ch/hpc), the HPC cluster at the University of Bern.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}